{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pothole Detection - YOLOv8 Training on Google Colab\n",
    "\n",
    "This notebook trains a YOLOv8n model for pothole detection.\n",
    "\n",
    "**Important**: Set Runtime → Change runtime type → GPU (T4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ultralytics\n",
    "!pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for saving models)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Dataset\n",
    "\n",
    "**Option A**: Upload the `datasets` folder from your local machine\n",
    "\n",
    "**Option B**: If you saved it to Google Drive, copy from there:\n",
    "```python\n",
    "!cp -r /content/drive/MyDrive/pothole_dataset /content/datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset (uncomment one option)\n",
    "\n",
    "# Option A: Upload from local computer\n",
    "# 1. Zip your ai-model/datasets folder locally\n",
    "# 2. Upload via Files panel on the left\n",
    "# 3. Uncomment and run:\n",
    "# !unzip -q datasets.zip -d /content/\n",
    "\n",
    "# Option B: Copy from Google Drive (if already uploaded)\n",
    "# !cp -r /content/drive/MyDrive/pothole_dataset /content/datasets\n",
    "\n",
    "# Verify dataset structure\n",
    "!ls -R /content/datasets/pothole_combined/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create data.yaml Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml\n",
    "data_yaml_content = \"\"\"# Dataset configuration for YOLOv8 training\n",
    "\n",
    "path: /content/datasets/pothole_combined  # Root path (Colab)\n",
    "train: train/images\n",
    "val: valid/images\n",
    "test: test/images\n",
    "\n",
    "# Class configuration\n",
    "nc: 1  # Number of classes\n",
    "names: ['pothole']  # Class names\n",
    "\"\"\"\n",
    "\n",
    "with open('/content/data.yaml', 'w') as f:\n",
    "    f.write(data_yaml_content)\n",
    "\n",
    "print(\"data.yaml created:\")\n",
    "!cat /content/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Preview Sample Images (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import glob\n",
    "\n",
    "def visualize_sample():\n",
    "    img_dir = '/content/datasets/pothole_combined/train/images'\n",
    "    lbl_dir = '/content/datasets/pothole_combined/train/labels'\n",
    "    \n",
    "    images = glob.glob(f\"{img_dir}/*\")\n",
    "    sample = random.choice(images)\n",
    "    img_name = os.path.basename(sample)\n",
    "    label_file = os.path.join(lbl_dir, img_name.rsplit('.', 1)[0] + '.txt')\n",
    "    \n",
    "    img = cv2.imread(sample)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(10, 8))\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            _, x_center, y_center, box_w, box_h = map(float, line.strip().split())\n",
    "            x_center_px = x_center * w\n",
    "            y_center_px = y_center * h\n",
    "            box_w_px = box_w * w\n",
    "            box_h_px = box_h * h\n",
    "            x1 = x_center_px - box_w_px / 2\n",
    "            y1 = y_center_px - box_h_px / 2\n",
    "            \n",
    "            rect = patches.Rectangle((x1, y1), box_w_px, box_h_px,\n",
    "                                     linewidth=2, edgecolor='red', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "    \n",
    "    ax.axis('off')\n",
    "    plt.title(f\"Sample: {img_name}\")\n",
    "    plt.show()\n",
    "\n",
    "visualize_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train YOLOv8n Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8n pretrained model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"This will take approximately 2-3 hours on Colab T4 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "results = model.train(\n",
    "    data='/content/data.yaml',\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    patience=20,\n",
    "    save=True,\n",
    "    project='/content/pothole_training',\n",
    "    name='yolov8n_run1',\n",
    "    device=0,  # Use GPU\n",
    "    \n",
    "    # Optimizer settings\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    \n",
    "    # Augmentation\n",
    "    augment=True,\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=10.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "metrics = model.val()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"mAP@50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check if meets requirements\n",
    "if metrics.box.map50 >= 0.75:\n",
    "    print(\"✓ Model meets minimum accuracy requirement (mAP@50 >= 75%)\")\n",
    "else:\n",
    "    print(\"⚠ Warning: Model accuracy below target (75%). Consider:\")\n",
    "    print(\"  - Training for more epochs\")\n",
    "    print(\"  - Using YOLOv8s (larger model)\")\n",
    "    print(\"  - Adding more training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"Training Results:\")\n",
    "display(Image(filename='/content/pothole_training/yolov8n_run1/results.png'))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "display(Image(filename='/content/pothole_training/yolov8n_run1/confusion_matrix.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Export to TFLite (float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "best_model = YOLO('/content/pothole_training/yolov8n_run1/weights/best.pt')\n",
    "\n",
    "print(\"Exporting to TFLite (float16)...\")\n",
    "tflite_path = best_model.export(\n",
    "    format='tflite',\n",
    "    imgsz=640,\n",
    "    half=True,  # float16 quantization\n",
    "    int8=False,\n",
    "    simplify=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTFLite model exported to: {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Verify TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Find the TFLite file\n",
    "import glob\n",
    "tflite_files = glob.glob('/content/pothole_training/yolov8n_run1/weights/*.tflite')\n",
    "tflite_model_path = [f for f in tflite_files if 'float16' in f][0]\n",
    "\n",
    "print(f\"Verifying: {tflite_model_path}\")\n",
    "\n",
    "# Check file size\n",
    "file_size_mb = os.path.getsize(tflite_model_path) / (1024 * 1024)\n",
    "print(f\"\\nFile size: {file_size_mb:.2f} MB\")\n",
    "\n",
    "if file_size_mb > 10:\n",
    "    print(\"⚠ WARNING: Model is larger than 10MB\")\n",
    "else:\n",
    "    print(\"✓ Model size is acceptable (<10MB)\")\n",
    "\n",
    "# Load and test\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(f\"\\nInput shape: {input_details[0]['shape']}\")\n",
    "print(f\"Input dtype: {input_details[0]['dtype']}\")\n",
    "print(f\"Output shape: {output_details[0]['shape']}\")\n",
    "print(f\"Output dtype: {output_details[0]['dtype']}\")\n",
    "\n",
    "# Test inference\n",
    "input_shape = input_details[0]['shape']\n",
    "test_input = np.random.random(input_shape).astype(np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], test_input)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(f\"\\n✓ Inference test successful\")\n",
    "print(f\"Output shape: {output_data.shape}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL READY FOR ANDROID DEPLOYMENT\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory in Google Drive\n",
    "!mkdir -p /content/drive/MyDrive/pothole_model\n",
    "\n",
    "# Copy model files\n",
    "!cp /content/pothole_training/yolov8n_run1/weights/best.pt /content/drive/MyDrive/pothole_model/\n",
    "!cp /content/pothole_training/yolov8n_run1/weights/*.tflite /content/drive/MyDrive/pothole_model/\n",
    "!cp /content/pothole_training/yolov8n_run1/results.csv /content/drive/MyDrive/pothole_model/\n",
    "!cp /content/pothole_training/yolov8n_run1/results.png /content/drive/MyDrive/pothole_model/\n",
    "!cp /content/pothole_training/yolov8n_run1/confusion_matrix.png /content/drive/MyDrive/pothole_model/\n",
    "\n",
    "print(\"\\n✓ Model files saved to Google Drive/pothole_model/\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Download the .tflite file from Google Drive\")\n",
    "print(\"2. Place it in: android/app/src/main/assets/models/\")\n",
    "print(\"3. Proceed with Android app development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Test Inference on Sample Image (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on a test image\n",
    "test_images = glob.glob('/content/datasets/pothole_combined/test/images/*')\n",
    "sample_image = random.choice(test_images)\n",
    "\n",
    "results = best_model.predict(source=sample_image, conf=0.5)\n",
    "\n",
    "# Display results\n",
    "from PIL import Image\n",
    "result_image = results[0].plot()\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(result_image)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Inference Result - Detected {len(results[0].boxes)} pothole(s)\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDetections: {len(results[0].boxes)}\")\n",
    "for i, box in enumerate(results[0].boxes):\n",
    "    print(f\"Pothole {i+1}: Confidence = {box.conf[0]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
